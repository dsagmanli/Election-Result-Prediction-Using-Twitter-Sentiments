{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb1c21a7-4b78-47aa-a5b9-705cd62d4189",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Unveiling Twitter Sentiments: A Big Data Dive into Twitter Sentiments during the 2020 US Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace9298a-58f8-4bbf-aaf5-936e719904f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook contains code for the Twitter Sentiment Analysis for Biden DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "129d68a7-f1e1-4fbf-993e-8e0c2d018229",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b7f9c21-b6b0-480c-8cef-be0b6e1fc4f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Installing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd7d7daf-1a13-411a-bb2b-be9ee41ba08f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: wordninja in /local_disk0/.ephemeral_nfs/envs/pythonEnv-270e679a-c4a6-4d87-9bd3-fab54f1a04ca/lib/python3.10/site-packages (2.0.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: langdetect in /local_disk0/.ephemeral_nfs/envs/pythonEnv-270e679a-c4a6-4d87-9bd3-fab54f1a04ca/lib/python3.10/site-packages (1.0.9)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from langdetect) (1.16.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: textblob in /local_disk0/.ephemeral_nfs/envs/pythonEnv-270e679a-c4a6-4d87-9bd3-fab54f1a04ca/lib/python3.10/site-packages (0.18.0.post0)\nRequirement already satisfied: nltk>=3.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-270e679a-c4a6-4d87-9bd3-fab54f1a04ca/lib/python3.10/site-packages (from textblob) (3.8.1)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.64.1)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2022.7.9)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.2.0)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.0.4)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#Installing necessary libraries \n",
    "%pip install wordninja\n",
    "%pip install langdetect\n",
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "271237d6-8166-4fa2-ae00-823bfc20e1d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Initiating Sprak Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21cdf26b-3117-485a-8e24-9ddd409e1139",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Twitter_Sentiment_Analysis\") \\\n",
    "    .appName(\"Group_Project\") \\\n",
    "    .appName(\"Biden_V1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b48872a-84e3-4867-aef5-477c9e09aa06",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected internal error when monkey patching sc._repr_html_: An error occurred while calling z:com.databricks.backend.daemon.driver.DriverLocal.commandContext. Trace:\npy4j.security.Py4JSecurityException: Method public static java.lang.ThreadLocal com.databricks.backend.daemon.driver.DriverLocal.commandContext() is not whitelisted on class class com.databricks.backend.daemon.driver.DriverLocal\n\tat py4j.security.WhitelistingPy4JSecurityManager.checkCall(WhitelistingPy4JSecurityManager.java:473)\n\tat py4j.Gateway.invoke(Gateway.java:305)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.139.64.10:40001\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.139.64.10:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://10.139.64.10:7077 appName=Databricks Shell>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10a15683-d2b5-4b18-a4e1-58b50604d5a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab2724d-b517-4514-b744-83a974a074c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import regexp_extract, lit, when, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import length, split, size, col, avg, regexp_replace\n",
    "from pyspark.sql.functions import col, trim\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import split, col, concat_ws\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import wordcloud\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# To ensure that each column's content is fully displayed without being truncated, we have set: \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "607350fa-4e25-4d1a-9faf-e5f7eeac186b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setting up Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c900d3b0-f6c0-4ee7-a108-5dd81bb6556e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1812042, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Defining my custom schema since we are not doing inferSchema= True, since it will take too much time \n",
    "custom_schema_B = StructType([\n",
    "    StructField(\"created_at\", StringType(), True),\n",
    "    StructField(\"tweet_id\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True),\n",
    "    StructField(\"likes\", StringType(), True),\n",
    "    StructField(\"retweet_count\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"user_name\", StringType(), True),\n",
    "    StructField(\"user_screen_name\", StringType(), True),\n",
    "    StructField(\"user_description\", StringType(), True),\n",
    "    StructField(\"user_join_date\", StringType(), True),\n",
    "    StructField(\"user_followers_count\", StringType(), True),\n",
    "    StructField(\"user_location\", StringType(), True),\n",
    "    StructField(\"lat\", StringType(), True),\n",
    "    StructField(\"long\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"state_code\", StringType(), True),\n",
    "    StructField(\"collected_at\", StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "# Reading the CSV file with custom schema\n",
    "df_b = spark.read.csv(\"/FileStore/tables/hashtag_joebiden-1.csv\", schema = custom_schema_B )\n",
    "df_b.persist()\n",
    "#running a count calculation to check how many rows and columns are present in the dataframe\n",
    "num_rows = df_b.count()\n",
    "num_columns = len(df_b.columns)\n",
    "print(\"DataFrame shape:\", (num_rows, num_columns))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1d464b-b5d8-4411-815d-e12c27ee1e81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- created_at: string (nullable = true)\n |-- tweet_id: string (nullable = true)\n |-- tweet: string (nullable = true)\n |-- likes: string (nullable = true)\n |-- retweet_count: string (nullable = true)\n |-- source: string (nullable = true)\n |-- user_id: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- user_screen_name: string (nullable = true)\n |-- user_description: string (nullable = true)\n |-- user_join_date: string (nullable = true)\n |-- user_followers_count: string (nullable = true)\n |-- user_location: string (nullable = true)\n |-- lat: string (nullable = true)\n |-- long: string (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- continent: string (nullable = true)\n |-- state: string (nullable = true)\n |-- state_code: string (nullable = true)\n |-- collected_at: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#printing the schema to check for the datatypes and everything else \n",
    "df_b.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1693aa6-bb61-4875-aee7-9348976daaa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_b= df_b.distinct() #we assumed that just because somebody retweets something doesn't mean they agree with it so we got rid of retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d0964c-956c-47d1-8fca-daaba77d3356",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Column details\n",
    "    created_at: Date and time of tweet creation\n",
    "    tweet_id: Unique ID of the tweet\n",
    "    tweet: Full tweet text \n",
    "    likes: Number of likes \n",
    "    retweet_count: Number of retweets\n",
    "    source: Utility used to post tweet\n",
    "    user_id: User ID of tweet creator\n",
    "    user_name: Username of tweet creator\n",
    "    user_screen_name: Screen name of tweet creator\n",
    "    user_description: Description of self by tweet creator\n",
    "    user_join_date: Join date of tweet creator\n",
    "    user_followers_count: Followers count on tweet creator\n",
    "    user_location: Location given on tweet creator's profile\n",
    "    lat: Latitude parsed from user_location\n",
    "    long: Longitude parsed from user_location\n",
    "    city: City parsed from user_location\n",
    "    country: Country parsed from user_location\n",
    "    state: State parsed from user_location\n",
    "    state_code: State code parsed from user_location\n",
    "    collected_at: Date and time tweet data was mined from twitter*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1560c018-8831-4f13-ad45-9390192c0010",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cba77a0-1e8b-42be-8c9c-282a3502d80d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### For Starters we are validating the datetime format of the tweets in the 'created_at' column and then if the format is wrong correcting them and then creating two new columns 'new_created_at' and 'new_tweet' to store the correct formatted tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab4f3c0c-c239-41f3-bacf-f79a8f12059a",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|new_created_at     |new_tweet                                                                                                                                                                                           |\n+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|NULL               |#ElSolLatino #yobrilloconelsol https://t.co/6FlCBWf1Mi\"                                                                                                                                             |\n|2020-10-15 00:00:20|@IslandGirlPRV @BradBeauregardJ @MeidasTouch This is how #Biden made his ! #TrumpIsNotAmerica !\\n                                                                                                   |\n|2020-10-15 00:00:01|#Elecciones2020 | En #Florida: #JoeBiden dice que #DonaldTrump solo se preocupa por él mismo. El demócrata fue anfitrión de encuentros de electores en #PembrokePines y #Miramar. Clic AQUÍ ⬇️⬇️⬇️\\n|\n|NULL               |🌐https://t.co/qhIWpIUXsT                                                                                                                                                                           |\n|NULL               |_                                                                                                                                                                                                   |\n|NULL               |@marciadorsey is @jack sick?\"                                                                                                                                                                       |\n|2020-10-15 00:00:18|#HunterBiden #HunterBidenEmails #JoeBiden #JoeBidenMustStepDown https://t.co/9enmxWvePm                                                                                                             |\n|NULL               |#AmyConeyBarrett #CoryBooker #Barrett #Booker #Trump #KamalaHarris #JoeBiden #SCOTUS #SupremeCourtConfirmation\"                                                                                     |\n|NULL               |created_at                                                                                                                                                                                          |\n|NULL               |That’s always been fine for @jack @vijaya @dickc @KatieS.                                                                                                                                           |\n|2020-10-15 00:00:23|\"\"\"IS THIS WRONG??!!\"\" Cory Booker's BRILLIANT Final Questioning of Trump Nominee Amy Coney Barrett https://t.co/gCTvVLl4CS                                                                         |\n|2020-10-15 00:00:22|#censorship #HunterBiden #Biden #BidenEmails #BidenEmail #Corruption https://t.co/C6clrtshQl                                                                                                        |\n|NULL               |but CCP from #China or porn on Twitter?                                                                                                                                                             |\n|NULL               |⠀⏹️ Facebook e Instagram                                                                                                                                                                            |\n|NULL               |https://t.co/uBqAFU86Ip\"                                                                                                                                                                            |\n|NULL               |⠀🌅 Miami: /elsollatinonewsmiami\"                                                                                                                                                                   |\n|NULL               |⠀🏙️ Philadelphia: /elsollatinonewspaper                                                                                                                                                            |\n|NULL               | *If you have any tips you'd like us to cover                                                                                                                                                       |\n|2020-10-15 00:00:21|@chrislongview Watching and setting dvr. Let’s give him bonus ratings!! #JoeBiden                                                                                                                   |\n|NULL               |⠀                                                                                                                                                                                                   |\n+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming valid datetime entries in 'created_at' are in the format \"YYYY-MM-DD HH:MM:SS\"\n",
    "datetime_pattern = r\"^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$\"\n",
    "\n",
    "# Adjust columns based on datetime validation\n",
    "df_b = df_b.withColumn(\n",
    "    \"new_created_at\",\n",
    "    when(regexp_extract(col(\"created_at\"), datetime_pattern, 0) != \"\", col(\"created_at\")).otherwise(lit(None))\n",
    ")\n",
    "\n",
    "df_b = df_b.withColumn(\n",
    "    \"new_tweet\",\n",
    "    when(regexp_extract(col(\"created_at\"), datetime_pattern, 0) == \"\", col(\"created_at\")).otherwise(col(\"tweet\"))\n",
    ")\n",
    "df_b.select(\"new_created_at\", \"new_tweet\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b9a5fa-73ad-46b9-b009-b1941a7d6eae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a550da99-78e1-4a74-ba85-a34c5c946f82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- tweet_id: string (nullable = true)\n |-- likes: string (nullable = true)\n |-- retweet_count: string (nullable = true)\n |-- source: string (nullable = true)\n |-- user_id: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- user_screen_name: string (nullable = true)\n |-- user_description: string (nullable = true)\n |-- user_join_date: string (nullable = true)\n |-- user_followers_count: string (nullable = true)\n |-- user_location: string (nullable = true)\n |-- lat: string (nullable = true)\n |-- long: string (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- continent: string (nullable = true)\n |-- state: string (nullable = true)\n |-- state_code: string (nullable = true)\n |-- collected_at: string (nullable = true)\n |-- new_created_at: string (nullable = true)\n |-- new_tweet: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#now dropping the old 'created_at' and 'tweet' columns since we dont need them anymore \n",
    "df_b = df_b.drop('created_at', 'tweet') \n",
    "#printing schema to check whether above columns have been dropped or not\n",
    "df_b.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de88912c-9bfc-48c4-a19b-e2950cbacfcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### There were empty tweets and they had to be removed since they dont provide any information to us "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c84e99a9-534f-43e9-9ebc-5b1323d810d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05434d9e-cef3-460d-9af7-b4c282092bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'tweet' is None or empty (including rows that only have whitespace)\n",
    "df_b = df_b.filter((col(\"new_tweet\").isNotNull()) & (trim(col(\"new_tweet\")) != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05498f6-1404-4bf2-bcba-34b1d0b5589c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------+--------+---------+--------------------+----------+--------------------+-------------------+--------------------+\n|            tweet_id|               likes|  retweet_count|              source|             user_id|           user_name|    user_screen_name|    user_description|      user_join_date|user_followers_count|       user_location|    lat|                long|         city| country|continent|               state|state_code|        collected_at|     new_created_at|           new_tweet|\n+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------+--------+---------+--------------------+----------+--------------------+-------------------+--------------------+\n|                 0.0|           TweetDeck|    360666534.0|  El Sol Latino News|     elsollatinonews|🌐 Noticias de in...|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|#ElSolLatino #yob...|\n|1.316529305006952...|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|2020-10-15 00:00:20|@IslandGirlPRV @B...|\n|1.316529221557252...|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|2020-10-15 00:00:01|#Elecciones2020 |...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|🌐https://t.co/qh...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|                   _|\n|                 0.0|  Twitter for iPhone|     19940334.0|Change Illinois |...|      changeillinois|Illinois, home of...| 2009-02-02 23:08:28|              1397.0|   Chicago, Illinois|  41.875561600000005|         -87.6244212|Chicago|United States of ...|North America|Illinois|       IL|2020-10-21 00:00:...|      NULL|                NULL|               NULL|@marciadorsey is ...|\n|1.31652929585929e+18|                 0.0|            0.0|    Twitter for iPad|         809904438.0|       Cheri A. 🇺🇸|        Biloximeemaw|Locked and loaded...| 2012-09-08 01:03:57|              6628.0|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|2020-10-21 00:00:...|2020-10-15 00:00:18|#HunterBiden #Hun...|\n|                 0.0|     Twitter Web App|    305727891.0|  Dose of Dissonance|     Dose_Dissonance|YOUTUBE CHANNEL: ...| 2011-05-26 18:09:32|              4622.0|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|2020-10-21 00:00:...|      NULL|                NULL|               NULL|#AmyConeyBarrett ...|\n|            tweet_id|               likes|  retweet_count|              source|             user_id|           user_name|    user_screen_name|    user_description|      user_join_date|user_followers_count|       user_location|    lat|                long|         city| country|continent|               state|state_code|        collected_at|               NULL|          created_at|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|That’s always bee...|\n|1.316529316507930...|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|2020-10-15 00:00:23|\"\"\"IS THIS WRONG?...|\n|1.316529312741253...|                 1.0|            0.0|     Twitter Web App|1.032806955356545...|      the Gold State|       theegoldstate|A Silicon Valley ...|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|2020-10-15 00:00:22|#censorship #Hunt...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|but CCP from #Chi...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|⠀⏹️ Facebook e In...|\n|                 0.0|     Twitter Web App|   3494182277.0|          Flag Waver|         Flag_Wavers|                NULL| 2015-08-30 19:38:21|              1536.0|Golden Valley Ari...|          46.3040364| -109.17143119999999|   NULL|United States of ...|North America| Montana|       MT|2020-10-21 00:00:...|      NULL|                NULL|               NULL|https://t.co/uBqA...|\n| 2011-08-23 15:33:45|Philadelphia, PA ...|       25.77427|           -80.19366|                NULL|United States of ...|       North America|             Florida|                  FL| 2020-10-21 00:00:00|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|⠀🌅 Miami: /elsol...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|⠀🏙️ Philadelphia...|\n| please DM or tag...|               390.0|California, USA|          36.7014631| -118.75599740000001|                NULL|United States of ...|       North America|          California|                  CA|2020-10-21 00:00:...|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL| *If you have any...|\n|1.316529308081557...|                 0.0|            0.0|  Twitter for iPhone|8.242596012018524...|       Michelle Ferg|       MichelleFerg4|                NULL| 2017-01-25 14:16:17|                27.0|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|2020-10-21 00:00:...|2020-10-15 00:00:21|@chrislongview Wa...|\n|                NULL|                NULL|           NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|   NULL|                NULL|         NULL|    NULL|     NULL|                NULL|      NULL|                NULL|               NULL|                   ⠀|\n+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------+--------+---------+--------------------+----------+--------------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "500a3541-adb5-4b37-b1b6-9c5b57fbbb58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1534036, 21)\n"
     ]
    }
   ],
   "source": [
    "#calculating how much the data is left after performing basic steps above the count had reduced significantly from \n",
    "num_rows = df_b.count()\n",
    "num_columns = len(df_b.columns)\n",
    "print(\"DataFrame shape:\", (num_rows, num_columns)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6035cf8-7f6e-4f1a-a1d4-2fe3f4900d36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c3f227a-c9e2-4536-b287-b1ea281c7a7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Now cleaning the tweets using the steps below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc1d4391-80b8-44b7-a844-abe9e65158df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Steps:\n",
    "        1. Convert text to lowercase to standardize it.\n",
    "        2. Remove contents in square brackets as they usually contain metadata like music info or citations.\n",
    "        3. Remove URLs to eliminate non-relevant text and potential privacy issues.\n",
    "        4. Remove any HTML or XML tags that may be present.\n",
    "        5. Remove new lines to clean up formatting.\n",
    "        6. Remove words containing numbers to focus only on textual content.\n",
    "        7. Remove mentions, useful in social media text processing to reduce noise.\n",
    "        8. Remove hashtags, useful for cleaning tags from social media texts.\n",
    "        9. Remove retweet artifacts, common in Twitter data.\n",
    "        10. Replace all non-word characters (except spaces) with spaces to clean up special characters or punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5305679f-4c75-478a-bc24-581c506969f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating a udf (user defined function) to remove all the special characters and such as hashtags, emojis, numbers, and lowering all chracters\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r'@[0-9]+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Registering the function as a UDF\n",
    "clean_udf = udf(clean, StringType())\n",
    "\n",
    "\n",
    "# Applying the UDF to the 'new_tweet' column to create 'cleaned_tweet'\n",
    "df_b = df_b.withColumn(\"cleaned_tweet\", clean_udf(col(\"new_tweet\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af6dc817-81bf-42b8-8b95-601dbd15faec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### At this point basic text pre-processing has been completed after removing retweets, setting correct datetime format, and all special characters and whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e424194-d767-4076-8e2f-5174c4e89ff8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'tweet' is None or empty (including rows that only have whitespace)\n",
    "df_b = df_b.filter((col(\"cleaned_tweet\").isNotNull()) & (trim(col(\"cleaned_tweet\")) != \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b841a2-ac3c-46ed-af3b-fe8851d642fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8baa25-2eea-4499-a1e1-d186d36984d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### LANGUAGE  DETECTION IS BEING CONDUCTED HERE TO ONLY INCLUDE THOSE TWEETS THAT ARE IN ENGLISH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af3d89f6-0574-4d09-b719-84f1a780bca8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import wordninja #Probabilistically split concatenated words using NLP based on English Wikipedia uni-gram frequencies.\n",
    "\n",
    "# Defining a UDF for preprocessing\n",
    "def split_words(text):\n",
    "    return ' '.join(wordninja.split(text))\n",
    "\n",
    "split_words_udf = udf(split_words, StringType())\n",
    "\n",
    "# Applying the UDF to DataFrame and creating two new columns processed_tweet and cleaned_weet using the split word udf\n",
    "df_b = df_b.withColumn(\"processed_tweet\", split_words_udf(col(\"cleaned_tweet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4258ca3-de1a-40f8-b47e-99d439e8305c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from langdetect import detect, LangDetectException\n",
    "def is_english(text):\n",
    "    # List of words that should always be considered English cause we were seeing some false negatives and thats not what we want\n",
    "    english_words = {'trump', 'biden', 'election', 'election2020', 'politics'}\n",
    "    \n",
    "    # Check if the text is exactly one of the specified words\n",
    "    if text in english_words:\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        # Returns True if the detected language is English\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        # If langdetect cannot understand the text, it assumes that the lang is non-English\n",
    "        return False\n",
    "\n",
    "# Registering the function as a UDF\n",
    "is_english_udf = udf(is_english, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d205ffe8-0865-43ac-a336-570263adb219",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a new column 'is_english' that indicates whether each tweet is in English\n",
    "df_b = df_b.withColumn(\"is_english\", is_english_udf(col(\"processed_tweet\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "816e310b-8627-40bc-b509-94ead5dd892f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231782d4-01b2-471b-9ae8-a3481d331526",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Counting the avg word length per tweet and some other metrics since these will be required later on to train ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca5358a4-435c-4a4f-afa2-6798483d4101",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------------+\n|tweet_len|word_count|      avg_word_len|\n+---------+----------+------------------+\n|       14|         2|               7.0|\n|        7|         3|2.3333333333333335|\n|       47|        12|3.9166666666666665|\n|      273|        69|3.9565217391304346|\n|       12|         1|              12.0|\n|      139|        25|              5.56|\n|       18|         1|              18.0|\n|       84|        17|4.9411764705882355|\n|       40|         6| 6.666666666666667|\n|      164|        29| 5.655172413793103|\n|       18|         5|               3.6|\n|       14|         7|               2.0|\n|      135|        15|               9.0|\n|       11|         2|               5.5|\n|      181|        32|           5.65625|\n|       12|         3|               4.0|\n|       52|         7| 7.428571428571429|\n|       41|         7| 5.857142857142857|\n|       69|        16|            4.3125|\n|        5|         2|               2.5|\n+---------+----------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Performing the necessary transformations to create \"cleaned_tweet\" column\n",
    "df_b = df_b.withColumn(\"cleaned_tweet\", regexp_replace(col(\"cleaned_tweet\"), \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "\n",
    "# Calculating the tweet length\n",
    "df_b = df_b.withColumn(\"tweet_len\", length(col(\"cleaned_tweet\")))\n",
    "\n",
    "# Calculating the  word count\n",
    "df_b = df_b.withColumn(\"word_count\", size(split(col(\"cleaned_tweet\"), \" \")))\n",
    "\n",
    "# Calculating the average word length\n",
    "df_b = df_b.withColumn(\"avg_word_len\", col(\"tweet_len\") / col(\"word_count\"))\n",
    "\n",
    "# Showing the results\n",
    "df_b.select(\"tweet_len\", \"word_count\", \"avg_word_len\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "852900ac-2e32-4d37-b727-eebc4c4949a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweet_id', 'likes', 'retweet_count', 'source', 'user_id', 'user_name', 'user_screen_name', 'user_description', 'user_join_date', 'user_followers_count', 'user_location', 'lat', 'long', 'city', 'country', 'continent', 'state', 'state_code', 'collected_at', 'new_created_at', 'new_tweet', 'cleaned_tweet', 'processed_tweet', 'is_english', 'tweet_len', 'word_count', 'avg_word_len']\n"
     ]
    }
   ],
   "source": [
    "#checking all columns of the transformed dataframe\n",
    "column_names = df_b.columns\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92e6a8d7-8e9b-4af3-b2c7-cfab9c379154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- tweet_id: string (nullable = true)\n |-- likes: string (nullable = true)\n |-- retweet_count: string (nullable = true)\n |-- source: string (nullable = true)\n |-- user_id: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- user_screen_name: string (nullable = true)\n |-- user_description: string (nullable = true)\n |-- user_join_date: string (nullable = true)\n |-- user_followers_count: string (nullable = true)\n |-- user_location: string (nullable = true)\n |-- lat: string (nullable = true)\n |-- long: string (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- continent: string (nullable = true)\n |-- state: string (nullable = true)\n |-- state_code: string (nullable = true)\n |-- collected_at: string (nullable = true)\n |-- new_created_at: string (nullable = true)\n |-- new_tweet: string (nullable = true)\n |-- cleaned_tweet: string (nullable = true)\n |-- processed_tweet: string (nullable = true)\n |-- is_english: boolean (nullable = true)\n |-- tweet_len: integer (nullable = true)\n |-- word_count: integer (nullable = false)\n |-- avg_word_len: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Filtering the DataFrame to keep only the tweets that are in English \n",
    "df_b = df_b.filter(col(\"is_english\") == True)\n",
    "df_b.printSchema()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61de2fce-d1fb-486e-bd55-5d991bad93bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Removing Stopwords from the cleaned_tweets column and creating a new column known as the filtered_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2445038-04e6-4273-b582-4f53570f172c",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|cleaned_tweet                                                                                                                                                                                                                                                                              |filtered_tweet                                                                                                                                                                                                                 |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|bidenharristosaveamerica                                                                                                                                                                                                                                                                   |biden harris save america                                                                                                                                                                                                      |\n|lists block                                                                                                                                                                                                                                                                                |lists block                                                                                                                                                                                                                    |\n|polls aren t votes  this is a referendum on our country s humanity  good vs  evil  sanity vs  mental illness                                                                                                                                                                               |polls aren votes referendum country humanity good vs evil sanity vs mental illness                                                                                                                                             |\n|turns out the poll that gave biden a  point lead in wisconsin wasn t a junk poll  and might be right on                                                                                                                                                                                    |turns poll gave biden point lead wisconsin wasn junk poll might right                                                                                                                                                          |\n|unprecedented times for the united states  is the country facing an existential crisis  and if so what might affect the outcome  uspolitics  vote trump biden                                                                                                                              |unprecedented times united states country facing existential crisis might affect outcome us politics vote trump biden                                                                                                          |\n| realdonaldtrump you re talking about everything that is already our reality  we can t do any of those things now because of you and your colossal incompetence  we re voting for biden so we can get our lives back after  months of your failure                                         |real donald trump re talking everything already reality things colossal incompetence re voting biden get lives back months failure                                                                                             |\n|  i absolutely believe biden will win  i just really want floridaforbiden  amp  a                                                                                                                                                                                                          |absolutely believe biden win really want florida biden amp                                                                                                                                                                     |\n|nbcnews cbsenews abcnews cnnnews msnbc  good grief  follow the money  you idiots  joebiden blatantly lied about discussing hunter s business with china  thank god for foxnews and tuckercarlson for interviewing tonybobulinski  ask sleepyjoe where he got his millions                  |nbc news cbs e news abc news cnn news msnbc good grief follow money idiots joe biden blatantly lied discussing hunter business china thank god fox news tucker carlson interviewing tony bob ul ski ask sleepy joe got millions|\n|can you believe the liberals   now they start blocking roads in the name of biden                                                                                                                                                                                                          |believe liberals start blocking roads name biden                                                                                                                                                                               |\n| bretbaier we spent time on the ukraine  amp  alexvindman call and tried to impeach a president  he never even met the president  bobalinksi did meet with biden  we have the laptop and the fbi verified it  so  yes  the story needs to be covered  hunter                               |bret baie r spent time ukraine amp alex v d man call tried impeach president never even met president bob links meet biden laptop fbi verified yes story needs covered hunter                                                  |\n| joebiden says the n word twice in  seconds                                                                                                                                                                                                                                                |joe biden says n word twice seconds                                                                                                                                                                                            |\n|ethics vs  corruption  truth vs  lies  love vs  hate                                                                                                                                                                                                                                       |ethics vs corruption truth vs lies love vs hate                                                                                                                                                                                |\n|with biden bombshells dropping daily  and the latest revelations from bobulinski tying  joebiden directly to hunterbiden s business dealings                                                                                                                                               |biden bombshells dropping daily latest revelations bob ul ski tying joe biden directly hunter biden business dealings                                                                                                          |\n|i tweet a lot because i can                                                                                                                                                                                                                                                                |tweet lot                                                                                                                                                                                                                      |\n|biden voters care about themselves  and they care about others  trump voters do as dear leader does  they eat and drink junk all day every day  they also don t care much about themselves or others  or they would want to wear a damn mask                                               |biden voters care care others trump voters dear leader eat drink junk day every day also care much others want wear damn mask                                                                                                  |\n| joebiden blacklivesmatter walterwallacejr defundthepolice mentalhealth philadelphia phillyprotests phillyriots policebrutality policeshooting blackmen whitesupremacy noantiblackracism fba                                                                                               |joe biden black lives matter walter wallace jr de fund police mental health philadelphia philly protests philly riots police brutality police shooting black men white supremacy anti black racism fba                         |\n| ap yeah and joebiden didn t sell out the usa to china       go fk yourself     boyswhocrywolf                                                                                                                                                                                             |ap yeah joe biden didn sell usa china go fk boys cry wolf                                                                                                                                                                      |\n| realdonaldtrump by the  time  donald j trump entered office    gt    he had  inherited from biden  amp  obama   gt  one of the strongest job markets in  america history    but covid  swiftly put an end to that  the unemployment rate shot     up   from when trump took office  gt cnt|real donald trump time donald j trump entered office gt inherited biden amp obama gt one strongest job markets america history c ovid swiftly put end unemployment rate shot trump took office gt cnt                          |\n|record set last night with tony bobulinski interview explaining joe biden s knowledge and participation in family business dealings in china and other countries bidencorruption plausabledeniability biden vote                                                                           |record set last night tony bob ul ski interview explaining joe biden knowledge participation family business dealings china countries biden corruption pla usable deniability biden vote                                       |\n|if you live in wisconsin  amp  want to changeyourvote                                                                                                                                                                                                                                      |live wisconsin amp want change vote                                                                                                                                                                                            |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the processed_tweet column into an array of words\n",
    "df_b = df_b.withColumn(\"cleaned_words\", split(col(\"processed_tweet\"), \" \"))\n",
    "\n",
    "# Create StopWordsRemover instance\n",
    "remover = StopWordsRemover(inputCol=\"cleaned_words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Remove stop words\n",
    "df_b = remover.transform(df_b)\n",
    "\n",
    "# Join the filtered words back into a single string\n",
    "df_b = df_b.withColumn(\"filtered_tweet\", concat_ws(\" \", col(\"filtered_words\")))\n",
    "\n",
    "# Show the DataFrame with filtered tweets\n",
    "df_b.select(\"cleaned_tweet\", \"filtered_tweet\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dabd14d5-1acd-43a0-90b0-f70a9e818822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['new_tweet', 'cleaned_tweet', 'processed_tweet','cleaned_words','filtered_words', 'source', 'user_name', 'user_screen_name', 'user_description', 'user_join_date', 'lat', 'long', 'user_id', 'tweet_id', 'new_created_at', 'collected_at','city','country','state','state_code','user_followers_count','retweet_count','likes']\n",
    "df_b = df_b.alias(\"df_transformed_3\")\n",
    "df_b = df_b.drop(*columns_to_drop)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe8efd4-4f2f-420e-a0f5-85fd4c11ad07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### NOW CACHING THE dataframe \"df_transformed_2\" since this will be used for sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd9a1e2-15ec-4577-93d2-44c0791e2a40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- user_location: string (nullable = true)\n |-- continent: string (nullable = true)\n |-- is_english: boolean (nullable = true)\n |-- tweet_len: integer (nullable = true)\n |-- word_count: integer (nullable = false)\n |-- avg_word_len: double (nullable = true)\n |-- filtered_tweet: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "df_b.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "988d4a90-e815-4f19-a946-8ec80980cdd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- user_location: string (nullable = true)\n |-- continent: string (nullable = true)\n |-- is_english: boolean (nullable = true)\n |-- tweet_len: integer (nullable = true)\n |-- word_count: integer (nullable = false)\n |-- avg_word_len: double (nullable = true)\n |-- filtered_tweet: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to keep only the tweets that are in English \n",
    "df_b = df_b.filter(col(\"is_english\") == True)\n",
    "df_b.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17906ead-742f-4bce-8da2-a200bf6a01dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[user_location: string, continent: string, is_english: boolean, tweet_len: int, word_count: int, avg_word_len: double, filtered_tweet: string]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a4b98a9-42c6-4e56-8975-c95b974e53d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9602f32e-ca54-4044-9440-11cbeee3106f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e0a7ff-c4ff-4f16-8b71-32d13e4d28e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Textblob\n",
    "### Creating Polarity and catching sentiments using textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2d43760-362c-40a5-9833-2656a37d1660",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, FloatType\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def get_analysis(score):\n",
    "    if score < 0:\n",
    "        return 'negative'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "# Register as UDFs\n",
    "subjectivity_udf = udf(get_subjectivity, FloatType())\n",
    "polarity_udf = udf(get_polarity, FloatType())\n",
    "analysis_udf = udf(get_analysis, StringType())\n",
    "\n",
    "\n",
    "# Applying UDFs to the DataFrame\n",
    "df_b = df_b.withColumn('subjectivity', subjectivity_udf(col('filtered_tweet')))\n",
    "df_b = df_b.withColumn('polarity', polarity_udf(col('filtered_tweet')))\n",
    "df_b = df_b.withColumn('sentiment', analysis_udf(col('polarity')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e7fd2ed-e3c1-45dd-a1a1-fb501f15d08d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4281566180901011>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_t\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'df_t' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'df_t' is not defined"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-4281566180901011>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_t\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
        "\u001B[0;31mNameError\u001B[0m: name 'df_t' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this was done to write the df back to the csv format since this is df will be used for training ML models\n",
    "#df_b.unpersist()\n",
    "#df_b.cache()\n",
    "#df_b.write.csv(\"/FileStore/tables/hashtag_joebiden-ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c6d5418-5d69-4bc5-81f0-2fa0659adf9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|sentiment| count|\n+---------+------+\n| positive|265495|\n|  neutral|385011|\n| negative|110781|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_b is your DataFrame with a 'sentiment' column\n",
    "sentiment_counts = df_b.groupBy(\"sentiment\").count()\n",
    "\n",
    "# Show the result\n",
    "sentiment_counts.show()\n",
    "#+---------+------+\n",
    "#|sentiment| count|\n",
    "#+---------+------+\n",
    "#| positive|265693|\n",
    "#|  neutral|385051|\n",
    "#| negative|110770|\n",
    "#+---------+------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5534de7-1336-4afb-80ae-6169dca6bf7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "TwitterSentimentAnalysis_V1_BIDEN",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
