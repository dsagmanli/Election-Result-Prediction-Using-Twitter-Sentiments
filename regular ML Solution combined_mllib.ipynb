{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6513e1c-ef35-41e4-ac43-cbc180a3115c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Unveiling Twitter Sentiments: A Big Data Dive into Twitter Sentiments during the 2020 US Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93159d0-3dec-43b9-9238-3c2fbb3e7bf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This Notebook contains Code for the **Regular ML approach** for both DataSets ( Biden and Trump ) so that we can compare it with our Local Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "767d2d68-fbfc-4767-80e3-ecfa464c922b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "227ccb48-709f-44cc-83ad-b8edf3aa4251",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Initiating SprakSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a50d11d-dc8c-4453-91d3-bc130ee056a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Twitter_Sentiment_Analysis\") \\\n",
    "    .appName(\"Group_Project\") \\\n",
    "    .appName(\"regular_ML_solution\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b2ab05-cfe7-4740-bb71-f57a0536248e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95fcb329-9858-406a-bea2-213eebc7f1c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import wordcloud\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# To ensure that each column's content is fully displayed without being truncated, you can set:\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a4dc8c1-9cb1-4ce1-a173-83a8b3bfd8b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4176043-ec2b-4003-8203-f8e61e7a3dd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Trump DataSet\n",
    "### Setting up Spark DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1767b27-71bd-4749-8bca-c7856565b5e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[user_location: string, continent: string, is_english: boolean, tweet_len: int, word_count: int, avg_word_len: double, filtered_tweet: string, subjectivity: float, polarity: float, sentiment: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the DF and casting column types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, DoubleType, FloatType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"user_location\", StringType(), True),\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"is_english\", BooleanType(), True),\n",
    "    StructField(\"tweet_len\", IntegerType(), True),\n",
    "    StructField(\"word_count\", IntegerType(), True),\n",
    "    StructField(\"avg_word_len\", DoubleType(), True),\n",
    "    StructField(\"filtered_tweet\", StringType(), True),\n",
    "    StructField(\"subjectivity\", FloatType(), True),\n",
    "    StructField(\"polarity\", FloatType(), True),\n",
    "    StructField(\"sentiment\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_t = spark.read.csv(\"/FileStore/tables/hashtag_donaldtrump-ML.csv\", schema=custom_schema)\n",
    "df_t.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651ff137-188b-4b2e-853b-83c03747692e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Dropping Columns that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b85247ca-02ae-4147-8583-b8ea9b97f7cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[tweet_len: int, word_count: int, avg_word_len: double, filtered_tweet: string, subjectivity: float, polarity: float, sentiment: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping some unneccessary columns\n",
    "columns_to_drop = ['user_location','continent','is_english']\n",
    "df_t = df_t.drop(*columns_to_drop) \n",
    "df_t.unpersist()\n",
    "df_t.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7442ec6c-3f56-44d8-894e-afd8f2a0cf43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------------+--------------------+------------+--------+---------+\n|tweet_len|word_count|     avg_word_len|      filtered_tweet|subjectivity|polarity|sentiment|\n+---------+----------+-----------------+--------------------+------------+--------+---------+\n|      270|        46|5.869565217391305|report administra...|       0.525|     0.3| positive|\n|      242|        54|4.481481481481482|white house put t...|  0.44722223|  -0.225| negative|\n|      125|        27| 4.62962962962963|curtis james jack...|         0.0|     0.0|  neutral|\n|       32|         6|5.333333333333333|ticker covers lat...|         0.9|     0.5| positive|\n|      157|        37|4.243243243243243|dj pot us pot gop...|         1.0|    -0.5| negative|\n+---------+----------+-----------------+--------------------+------------+--------+---------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_t.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d722b29-8abc-4086-93fd-42a4e22a8a73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensuring filtered_tweet is not null\n",
    "df_t = df_t.filter(df_t.filtered_tweet.isNotNull() & (df_t.filtered_tweet != ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba59154-a2b1-4df5-b35a-e72002eb4b5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "642d2370-dfc0-4f53-9ca0-09a808a4a7e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Building ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae729257-3b57-4b0b-902c-110ff8ef4fd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "# Feature Preparation\n",
    "def parse_point(row):\n",
    "    features = [row['tweet_len'], row['word_count'], row['avg_word_len'], row['subjectivity']]\n",
    "    label = 1.0 if row['sentiment'] == 'positive' else 0.0\n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "# Preparing the training and test data\n",
    "positive_negative_df_t = df_t.filter((df_t[\"sentiment\"] == \"positive\") | (df_t[\"sentiment\"] == \"negative\"))\n",
    "train_df_t, test_df_t = positive_negative_df_t.randomSplit([0.7, 0.3], seed=654321)\n",
    "\n",
    "train_rdd_t = train_df_t.rdd.map(parse_point)\n",
    "test_rdd_t = test_df_t.rdd.map(parse_point)\n",
    "\n",
    "# Model Training\n",
    "model_t = LogisticRegressionWithLBFGS.train(train_rdd_t)\n",
    "\n",
    "# Predictions\n",
    "predictions_t = test_rdd_t.map(lambda p: (float(model_t.predict(p.features)), p.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3208d89e-a96b-46f9-9e82-88580e46144a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1407a1a8-897b-4586-ada7-5a79dd7fb2fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Performing Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdbf0ab-fa2e-4fc2-9362-54db98f73ba0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Evaluating the performance of our model using Mean Absolute Error, as it is commonly used for regression models. Using part of the lecture material to calculate mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06cfafea-be0a-41a8-a307-387d946d68e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.36129391646802783\n"
     ]
    }
   ],
   "source": [
    "# Calculate absolute errors\n",
    "absolute_errors_t = predictions_t.map(lambda pred: abs(pred[0] - pred[1]))\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mean_absolute_error_t = absolute_errors_t.mean()\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eb155a7-33a0-45ab-a6b3-c530d668d9b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afa35551-e542-4f04-b6c1-3c0069ebd22d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Classifying Neutral Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b2926e2-f4b0-481e-b3ab-ca131bea4abd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Until now we trained and tested on our positive-negative training set. Now we will classify the neutral tweets into positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49d687f3-af3e-47a3-9abd-27ccabb3b468",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "neutral_df_t = df_t.filter(df_t[\"sentiment\"] == \"neutral\")\n",
    "neutral_df_t = neutral_df_t.drop(\"filtered_tweet\", \"polarity\")\n",
    "neutral_rdd_t = neutral_df_t.rdd.map(parse_point)\n",
    "neutral_predictions_t = neutral_rdd_t.map(lambda p: (float(model_t.predict(p.features)), p.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b213065c-004e-4fd3-a60b-6a51ec3acdfd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e83051-74bf-41c2-a543-be9814060361",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We get the count of positive, negative, positive-predicted-neutral and negative-predicted neutral tweets to see total positive tweets / all tweets for this candidate. We will then compare this ratio with the other candidate. Our assumption is that whoever has the higher ratio should win. We will see if the person with the higher ratio actually won to see if twitter sentiments actually reflect real election outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67d53888-8c58-4853-87b1-6eab4305754e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Predictions Coming From Neutrals: 524360\nNegative Predictions Coming From Neutrals: 1144\nPositive Predictions: 327997\nNegative Predictions: 186253\nPositive/All Tweets Ratio For Trump: 0.8197679451100933\n"
     ]
    }
   ],
   "source": [
    "# We get the count of positive, negative, positive-predicted-neutral and negative-predicted neutral tweets to see total positive tweets / all tweets for this candidate. We will then compare this ratio with the other candidate. Our assumption is that whoever has the higher ratio should win. We will see if the person with the higher ratio actually won to see if twitter sentiments actually reflect real election outcome.\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "positive_neutral_count = neutral_predictions_t.filter(lambda pred: pred[0] == 1.0).count()\n",
    "\n",
    "negative_neutral_count = neutral_predictions_t.filter(lambda pred: pred[0] == 0.0).count()\n",
    "\n",
    "positive_count = positive_negative_df_t.filter(col(\"sentiment\") == \"positive\").count()\n",
    "\n",
    "negative_count = positive_negative_df_t.filter(col(\"sentiment\") == \"negative\").count()\n",
    "\n",
    "sum = positive_neutral_count + negative_neutral_count + positive_count + negative_count\n",
    "positives = positive_neutral_count + positive_count\n",
    "ratio = positives/sum\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Positive Predictions Coming From Neutrals:\", positive_neutral_count)\n",
    "print(\"Negative Predictions Coming From Neutrals:\", negative_neutral_count)\n",
    "print(\"Positive Predictions:\", positive_count)\n",
    "print(\"Negative Predictions:\", negative_count)\n",
    "print(\"Positive/All Tweets Ratio For Trump:\", ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76191ed9-e895-4ba3-beed-88a779e7c231",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2289f25-214d-4d66-ac33-d231f943d6fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Biden Dataset\n",
    "Now, we do the same things again for Joe Biden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811df520-5dfc-455d-a8ff-3b8ec4639f77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setting up Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25012f6e-4151-4082-870f-d460de12f93d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[user_location: string, continent: string, is_english: boolean, tweet_len: int, word_count: int, avg_word_len: double, filtered_tweet: string, subjectivity: float, polarity: float, sentiment: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b = spark.read.csv(\"/FileStore/tables/hashtag_joebiden-ML.csv\", schema=custom_schema)\n",
    "df_b.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09fde80f-dcfd-4033-9ed7-bf291e2b45ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Dropping Columns that are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9e87f18-4efd-4f2d-a44b-c82fcf19729a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[tweet_len: int, word_count: int, avg_word_len: double, filtered_tweet: string, subjectivity: float, polarity: float, sentiment: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping some unneccessary columns\n",
    "columns_to_drop = ['user_location','continent','is_english']\n",
    "df_b = df_b.drop(*columns_to_drop) \n",
    "df_b.unpersist()\n",
    "df_b.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6baa7a-a0d8-4360-93e1-36fc8062a4eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensuring filtered_tweet is not null\n",
    "df_b = df_b.filter(df_b.filtered_tweet.isNotNull() & (df_b.filtered_tweet != ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df60b6f-8449-457c-9091-a6f85817515e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dfce246-e9c5-498d-b922-c6d5ff8d48cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Building ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362f50c9-d3a7-41ae-bdeb-89ca636c37f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the training and test data\n",
    "positive_negative_df_b = df_b.filter((df_b[\"sentiment\"] == \"positive\") | (df_b[\"sentiment\"] == \"negative\"))\n",
    "train_df_b, test_df_b = positive_negative_df_b.randomSplit([0.7, 0.3], seed=654321)\n",
    "\n",
    "train_rdd_b = train_df_b.rdd.map(parse_point)\n",
    "test_rdd_b = test_df_b.rdd.map(parse_point)\n",
    "\n",
    "# Model Training\n",
    "model_b = LogisticRegressionWithLBFGS.train(train_rdd_b)\n",
    "\n",
    "# Predictions\n",
    "predictions_b = test_rdd_b.map(lambda p: (float(model_b.predict(p.features)), p.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50e7718-8da8-4e29-a3d5-a2d2219f4d9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Performing Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a51c867-e640-4e01-8caa-49a4707ad298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2951331740553935\n"
     ]
    }
   ],
   "source": [
    "# Calculate absolute errors\n",
    "absolute_errors_b = predictions_b.map(lambda pred: abs(pred[0] - pred[1]))\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mean_absolute_error_b = absolute_errors_b.mean()\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7026eb8d-e28d-4d7a-b452-f68a316bbe7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf8cbc5-e95e-461d-903e-b8eb72ce1479",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Classifying Neutral Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13fbdb84-beba-4a9f-ae53-a709a0a76c41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "neutral_df_b = df_b.filter(df_b[\"sentiment\"] == \"neutral\")\n",
    "neutral_df_b = neutral_df_b.drop(\"filtered_tweet\", \"polarity\")\n",
    "neutral_rdd_b = neutral_df_b.rdd.map(parse_point)\n",
    "neutral_predictions_b = neutral_rdd_b.map(lambda p: (float(model_b.predict(p.features)), p.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ec42b31-38e5-4a5e-9ad1-a40a338dd647",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4085935d-7d8a-4b01-8d2f-e82bb557336f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Calculating Winning Ratio based on tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b092406a-7fa2-4537-90c1-fa6ad3b70e79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Predictions Coming From Neutrals: 382414\nNegative Predictions Coming From Neutrals: 4\nPositive Predictions: 265638\nNegative Predictions: 110776\nPositive/All Tweets Ratio For Biden: 0.8540124823412824\n"
     ]
    }
   ],
   "source": [
    "# We get the count of positive, negative, positive-predicted-neutral and negative-predicted neutral tweets to see total positive tweets / all tweets for this candidate. We will then compare this ratio with the other candidate. Our assumption is that whoever has the higher ratio should win. We will see if the person with the higher ratio actually won to see if twitter sentiments actually reflect real election outcome.\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "positive_neutral_count = neutral_predictions_b.filter(lambda pred: pred[0] == 1.0).count()\n",
    "\n",
    "negative_neutral_count = neutral_predictions_b.filter(lambda pred: pred[0] == 0.0).count()\n",
    "\n",
    "positive_count = positive_negative_df_b.filter(col(\"sentiment\") == \"positive\").count()\n",
    "\n",
    "negative_count = positive_negative_df_b.filter(col(\"sentiment\") == \"negative\").count()\n",
    "\n",
    "sum = positive_neutral_count + negative_neutral_count + positive_count + negative_count\n",
    "positives = positive_neutral_count + positive_count\n",
    "ratio = positives/sum\n",
    "\n",
    "\n",
    "# Display the counts\n",
    "print(\"Positive Predictions Coming From Neutrals:\", positive_neutral_count)\n",
    "print(\"Negative Predictions Coming From Neutrals:\", negative_neutral_count)\n",
    "print(\"Positive Predictions:\", positive_count)\n",
    "print(\"Negative Predictions:\", negative_count)\n",
    "print(\"Positive/All Tweets Ratio For Biden:\", ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3142a520-2e68-42e7-af93-bdb3a35b49f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###.                 The regular MLlib approach also says Biden should win due to his ratio being bigger, which he did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a2a7036-b891-4f64-b395-217fc06cb508",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "regular ML Solution combined_mllib",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
